{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Build a Simple LLM Application with LCEL\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/tutorials/llm_chain/)"
   ],
   "id": "7a2f727e71665314"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "4e76def53c1df9a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### LangSmith\n",
    "\n",
    "> it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.  \n",
    "> The best way to do this is with LangSmith."
   ],
   "id": "edf26bea38384b52"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-tutorials\""
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Using Language Models\n",
    "\n",
    "First, I decided to use the OpenAI language model.  \n",
    "Create .env file under notebooks directory and set the following environment variables.\n",
    "\n",
    "```\n",
    "LANGCHAIN_API_KEY=**********\n",
    "OPENAI_API_KEY=**********\n",
    "```"
   ],
   "id": "3d220446964877af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ],
   "id": "4d50f2a2233e135c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4\")\n",
    "# maybe not available because of legacy(?)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"text-davinci-003\")\n",
    "# deprecated\n",
    "\n",
    "llm_4o = ChatOpenAI(model=\"gpt-4o\")\n",
    "# llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_35 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm_cheap = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=100, top_p=0.1)"
   ],
   "id": "89412eff6f3a7662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]"
   ],
   "id": "ca6400e38c95a6ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_4o.invoke(messages)",
   "id": "58cbbf2f3139031a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-4o\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-4o-2024-08-06',\n",
    "        'system_fingerprint': 'fp_e5e4913e83',\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "644178b472af2636"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_35.invoke(messages)",
   "id": "eb1944243b17b0c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-3.5-turbo\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "8760b1116cd26823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_cheap.invoke(messages)",
   "id": "7ed42e965a52c2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-3.5-turbo, max_tokens=100, top_p=0.1\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "63fba7585851ec95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## OutputParsers\n",
    "\n",
    "> We can parse out just this response by using a simple output parser.\n",
    "\n",
    "API Reference: [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
   ],
   "id": "1b7bc2c1914f1e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ],
   "id": "318c9810704cb367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm_4o_mini.invoke(messages)"
   ],
   "id": "26089f3d247a21b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parser.invoke(result)",
   "id": "8bf9e05b62a78db4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'\n",
    "```"
   ],
   "id": "6498e1e2cabbb5e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = llm_4o_mini | parser",
   "id": "6415a4f21062e26c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain.invoke(messages)",
   "id": "9c4129701ed39886",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'\n",
    "```"
   ],
   "id": "99109fe40fe2036a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LangSmith trace\n",
    "```\n",
    "RunnableSequence\n",
    "    human: hi!\n",
    "    „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "    0.98s\n",
    "    22 (tokens)\n",
    "    $0.0000042\n",
    "    ChatOpenAI\n",
    "        human: hi!\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.98s\n",
    "        22 (tokens)\n",
    "        $0.0000042\n",
    "        seq:step:1\n",
    "        ls_provider: openai\n",
    "        ls_model_name: gpt-4o-mini\n",
    "        ls_model_type: chat\n",
    "        ls_temperature: 0.7\n",
    "    StrOutputParser\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.00s\n",
    "        0 (tokens)\n",
    "        seq:step:2\n",
    "```\n"
   ],
   "id": "4eb26b80d5467940"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b1e4cff8c9a0916e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
