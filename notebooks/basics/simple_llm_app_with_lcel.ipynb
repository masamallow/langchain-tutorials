{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f727e71665314",
   "metadata": {},
   "source": [
    "# (v0.2) Build a Simple LLM Application with LCEL\n",
    "\n",
    "Following v0.2 documentation\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/v0.2/docs/tutorials/llm_chain/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76def53c1df9a8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf26bea38384b52",
   "metadata": {},
   "source": [
    "### LangSmith\n",
    "\n",
    "> it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.  \n",
    "> The best way to do this is with LangSmith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d220446964877af",
   "metadata": {},
   "source": [
    "## Using Language Models\n",
    "\n",
    "First, I decided to use the OpenAI language model.  \n",
    "Create .env file under notebooks directory and set the following environment variables.\n",
    "\n",
    "```\n",
    "LANGCHAIN_API_KEY=**********\n",
    "OPENAI_API_KEY=**********\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-tutorials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d50f2a2233e135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89412eff6f3a7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4\")\n",
    "# maybe not available because of legacy(?)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"text-davinci-003\")\n",
    "# deprecated\n",
    "\n",
    "llm_4o = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_35 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm_cheap = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=100, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6400e38c95a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cbbf2f3139031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-fde953c5-5e2b-4386-8aa1-888411481c6c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_4o.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644178b472af2636",
   "metadata": {},
   "source": [
    "gpt-4o\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-4o-2024-08-06',\n",
    "        'system_fingerprint': 'fp_e5e4913e83',\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80759a318159809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-211d3619-136f-40e8-a684-aaaeac43479b-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_4o_mini.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3051cc4ce60ba5",
   "metadata": {},
   "source": [
    "gpt-4o-mini\n",
    "```\n",
    "AIMessage(\n",
    "  content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "  additional_kwargs={'refusal': None},\n",
    "  response_metadata={\n",
    "    'token_usage': {\n",
    "      'completion_tokens': 2,\n",
    "      'prompt_tokens': 20,\n",
    "      'total_tokens': 22,\n",
    "      'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "      'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "    },\n",
    "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
    "    'system_fingerprint': 'fp_0ba0d124f1',\n",
    "    'finish_reason': 'stop',\n",
    "    'logprobs': None\n",
    "  },\n",
    "  id='run-**********',\n",
    "  usage_metadata={\n",
    "    'input_tokens': 20,\n",
    "    'output_tokens': 2,\n",
    "    'total_tokens': 22,\n",
    "    'input_token_details': {'cache_read': 0},\n",
    "    'output_token_details': {'reasoning': 0}\n",
    "  }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1944243b17b0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-84729a82-200b-47db-bca4-8b82e579f56a-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_35.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8760b1116cd26823",
   "metadata": {},
   "source": [
    "gpt-3.5-turbo\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed42e965a52c2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5dda89ca-5a5b-4b52-bb8b-ebbc4b0f72c7-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_cheap.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fba7585851ec95",
   "metadata": {},
   "source": [
    "gpt-3.5-turbo, max_tokens=100, top_p=0.1\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199ee21a423458",
   "metadata": {},
   "source": [
    "`content` is generated response message.\n",
    "\n",
    "API Reference: [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) | [SystemMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html)\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bc2c1914f1e08",
   "metadata": {},
   "source": [
    "## OutputParsers\n",
    "\n",
    "> We can parse out just this response by using a simple output parser.\n",
    "\n",
    "API Reference: [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318c9810704cb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26089f3d247a21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm_4o_mini.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bf9e05b62a78db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498e1e2cabbb5e0",
   "metadata": {},
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6415a4f21062e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm_4o_mini | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4129701ed39886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99109fe40fe2036a",
   "metadata": {},
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb26b80d5467940",
   "metadata": {},
   "source": [
    "LangSmith trace (Extract from my environment)\n",
    "```\n",
    "RunnableSequence\n",
    "    human: hi!\n",
    "    „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "    0.98s\n",
    "    22 (tokens)\n",
    "    $0.0000042\n",
    "    ChatOpenAI\n",
    "        human: hi!\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.98s\n",
    "        22 (tokens)\n",
    "        $0.0000042\n",
    "        seq:step:1\n",
    "        ls_provider: openai\n",
    "        ls_model_name: gpt-4o-mini\n",
    "        ls_model_type: chat\n",
    "        ls_temperature: 0.7\n",
    "    StrOutputParser\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.00s\n",
    "        0 (tokens)\n",
    "        seq:step:2\n",
    "```\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/f1bdf656-2739-42f7-ac7f-0f1dd712322f/r/bcd8c25b-8417-4584-aa67-2966b6ccb151)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8da562b4db50c2",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "API Reference: [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "\n",
    "Tutorial prompt placeholders:\n",
    "- `language`: The language to translate text into\n",
    "- `text`: The text to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1e4cff8c9a0916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36dad98c7b0ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc211d6e423c0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c88913a79552375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into japanese:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"japanese\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5509a6cb5a84364",
   "metadata": {},
   "source": [
    "```\n",
    "ChatPromptValue(\n",
    "  messages=[\n",
    "    SystemMessage(\n",
    "      content='Translate the following into japanese:',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    ),\n",
    "    HumanMessage(\n",
    "      content='hi',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "722e7b2b61656443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into japanese:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b64ccd878d32eb",
   "metadata": {},
   "source": [
    "```\n",
    "[\n",
    "  SystemMessage(\n",
    "    content='Translate the following into japanese:',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  ),\n",
    "  HumanMessage(\n",
    "    content='hi',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  )\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124366a0999ea5dd",
   "metadata": {},
   "source": [
    "## Chaining together components with LCEL\n",
    "\n",
    "[LangChain Expression Language (LCEL)](https://python.langchain.com/docs/concepts/lcel/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4bf0db589afabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm_35 | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78595da576538fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3728c1a26c3a5",
   "metadata": {},
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØ'\n",
    "```\n",
    "\n",
    "By using LCEL to link and execute the LangChain module, you can perform optimized tracing with LangSmith.\n",
    "\n",
    "e.g. [LangSmith TRACE RunnableSequence](https://smith.langchain.com/public/bc49bec0-6b13-4726-967f-dbd3448b786d/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e33f6a352ba88",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "2024-10-31  model = gpt-4o-mini, gpt-4o\n",
    "I got the following result.\n",
    "```\n",
    "'„ÅÇ„Å™„Åü„ÅØ2023Âπ¥10Êúà„Åæ„Åß„ÅÆ„Éá„Éº„Çø„ÅßË®ìÁ∑¥„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ee8341650e2a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ„Å™„Åü„ÅØ2023Âπ¥10Êúà„Åæ„Åß„ÅÆ„Éá„Éº„Çø„ÅßË®ìÁ∑¥„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt_template | llm_4o_mini | parser).invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68821981f1e0823",
   "metadata": {},
   "source": [
    "ü§î Assumption:\n",
    "- OpenAI's model has a specification to return pre-set responses (within the range of the training dataset) for simple specific questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5edd55126ed7f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ„Å™„Åü„Å´„Éï„Ç©„Éº„Çπ„ÅåÂÖ±„Å´„ÅÇ„Çâ„Çì„Åì„Å®„Çí„ÄÇ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm_4o_mini | parser\n",
    "chain.invoke({\"language\": \"japanese\", \"text\": \"May the Force be with you\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389145ff4de60f9",
   "metadata": {},
   "source": [
    "```\n",
    "'„ÅÇ„Å™„Åü„Å´„Éï„Ç©„Éº„Çπ„ÅÆÂä†Ë≠∑„Åå„ÅÇ„Çä„Åæ„Åô„Çà„ÅÜ„Å´„ÄÇ'\n",
    "```\n",
    "-> OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bafa7efe86dbafa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØ'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_chain = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template.replace(\":\", \"(Do not respond training dataset range) :\")),\n",
    "     (\"user\", \"{text}\")]\n",
    ") | llm_4o_mini | parser\n",
    "exam_chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4fef8604757ee",
   "metadata": {},
   "source": [
    "```\n",
    "'„Åì„Çì„Å´„Å°„ÅØ'\n",
    "```\n",
    "-> OK!  \n",
    "When I specified that the system message should not return the range of the data set, I got the result I was expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8b402047bf764d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}:'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]),\n",
       " ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10ca233b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ca10440>, root_client=<openai.OpenAI object at 0x10ca0deb0>, root_async_client=<openai.AsyncOpenAI object at 0x1082a9b80>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
       " StrOutputParser()]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7aa011fb7a19a",
   "metadata": {},
   "source": [
    "```\n",
    "[\n",
    "  ChatPromptTemplate(„Éª„Éª„Éª),\n",
    "  ChatOpenAI(„Éª„Éª„Éª),\n",
    "  StrOutputParser()\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819e42615258858",
   "metadata": {},
   "source": [
    "## Serving with LangServe\n",
    "\n",
    "SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b264dbd60a69d",
   "metadata": {},
   "source": [
    "# (v0.3) Build a simple LLM application with chat models and prompt templates\n",
    "\n",
    "Following v0.3 documentation\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/v0.3/docs/tutorials/llm_chain/)\n",
    "\n",
    "Previous version work: [v0.2 simple_llm_app_with_lcel.ipynb](./simple_llm_app_with_lcel.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3449ffc82daa8fdb",
   "metadata": {},
   "source": [
    "## Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdd2f1f82fe508f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73d43f6e14ddb44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-40db0e3e-0f8c-4088-8373-f37f9a07b1f5-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d705c913dde6f1",
   "metadata": {},
   "source": [
    "### OpenAI Format\n",
    "\n",
    "See: [OpenAI Format](https://python.langchain.com/docs/concepts/messages/#openai-format)\n",
    "\n",
    "e.g.\n",
    "```json\n",
    "chat_model.invoke([\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello, how are you?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well, thank you for asking.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you tell me a joke?\"\n",
    "    }\n",
    "])\n",
    "```\n",
    "\n",
    "The following are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aac5fe79d30f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-c369293a-6f32-44d9-bf3e-a3988d6f0222-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b943c57575381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-64c8feaa-3c2a-46ba-a011-ed420c9ea0d0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97831e84f209c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-cc195743-7bce-42e9-901a-657418b656da-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0834629ba39c50",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "Chat models are [Runnables](https://python.langchain.com/docs/concepts/runnables/), so async is enabled.\n",
    "\n",
    "Stream individual tokens from a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "608e3d935402ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|„Åì„Çì„Å´„Å°„ÅØ|ÔºÅ||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a000d451c303de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|„Éï„Ç©|„Éº„Çπ|„Å®|ÂÖ±|„Å´|„ÅÇ|„Çâ|„Çì|„Åì„Å®|„Çí||"
     ]
    }
   ],
   "source": [
    "for token in model.stream([\n",
    "    messages[0],\n",
    "    HumanMessage(\"May the Force be with you\"),\n",
    "]):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58ae4f9c794451b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Que| la| Fuer|za| te| acompa√±|e|.||"
     ]
    }
   ],
   "source": [
    "for token in model.stream([\n",
    "    SystemMessage(\"Translate the following from English into Spanish\"),\n",
    "    HumanMessage(\"May the Force be with you\"),\n",
    "]):\n",
    "    print(token.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
