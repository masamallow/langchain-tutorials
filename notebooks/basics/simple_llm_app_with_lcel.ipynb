{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2f727e71665314",
   "metadata": {},
   "source": [
    "# (v0.2) Build a Simple LLM Application with LCEL\n",
    "\n",
    "Following v0.2 documentation\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/v0.2/docs/tutorials/llm_chain/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76def53c1df9a8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf26bea38384b52",
   "metadata": {},
   "source": [
    "### LangSmith\n",
    "\n",
    "> it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.  \n",
    "> The best way to do this is with LangSmith."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d220446964877af",
   "metadata": {},
   "source": [
    "## Using Language Models\n",
    "\n",
    "First, I decided to use the OpenAI language model.  \n",
    "Create .env file under notebooks directory and set the following environment variables.\n",
    "\n",
    "```\n",
    "LANGCHAIN_API_KEY=**********\n",
    "OPENAI_API_KEY=**********\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-tutorials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d50f2a2233e135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89412eff6f3a7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4\")\n",
    "# maybe not available because of legacy(?)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"text-davinci-003\")\n",
    "# deprecated\n",
    "\n",
    "llm_4o = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_35 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm_cheap = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=100, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6400e38c95a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cbbf2f3139031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-fd4deaf6-ae22-4649-946c-db8865caa88b-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_4o.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9e2109d58b45a",
   "metadata": {},
   "source": [
    "gpt-4o\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-4o-2024-08-06',\n",
    "        'system_fingerprint': 'fp_e5e4913e83',\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ba4531e2c09855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-3a17ff35-1a72-4d31-b547-ce8ba04a21c9-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_4o_mini.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96864a15adc40ce",
   "metadata": {},
   "source": [
    "gpt-4o-mini\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "  content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "  additional_kwargs={'refusal': None},\n",
    "  response_metadata={\n",
    "    'token_usage': {\n",
    "      'completion_tokens': 2,\n",
    "      'prompt_tokens': 20,\n",
    "      'total_tokens': 22,\n",
    "      'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "      'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "    },\n",
    "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
    "    'system_fingerprint': 'fp_0ba0d124f1',\n",
    "    'finish_reason': 'stop',\n",
    "    'logprobs': None\n",
    "  },\n",
    "  id='run-**********',\n",
    "  usage_metadata={\n",
    "    'input_tokens': 20,\n",
    "    'output_tokens': 2,\n",
    "    'total_tokens': 22,\n",
    "    'input_token_details': {'cache_read': 0},\n",
    "    'output_token_details': {'reasoning': 0}\n",
    "  }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152be3f05e8a782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8942ba73-458d-46f4-9dce-73a005b30fa0-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_35.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e96fb8bf2b6965",
   "metadata": {},
   "source": [
    "gpt-3.5-turbo\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9679682de00bc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-471b86b3-0d3b-444e-a9b9-15049c8492ce-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_cheap.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fba7585851ec95",
   "metadata": {},
   "source": [
    "gpt-3.5-turbo, max_tokens=100, top_p=0.1\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='„Åì„Çì„Å´„Å°„ÅØÔºÅ',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199ee21a423458",
   "metadata": {},
   "source": [
    "`content` is generated response message.\n",
    "\n",
    "API Reference: [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) | [SystemMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html)\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bc2c1914f1e08",
   "metadata": {},
   "source": [
    "## OutputParsers\n",
    "\n",
    "> We can parse out just this response by using a simple output parser.\n",
    "\n",
    "API Reference: [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318c9810704cb367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26089f3d247a21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm_4o_mini.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a98808111160153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2787a72785592dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = llm_4o_mini | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff35e0863f3f382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØÔºÅ'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb26b80d5467940",
   "metadata": {},
   "source": [
    "LangSmith trace (Extract from my environment)\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "RunnableSequence\n",
    "    human: hi!\n",
    "    „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "    0.98s\n",
    "    22 (tokens)\n",
    "    $0.0000042\n",
    "    ChatOpenAI\n",
    "        human: hi!\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.98s\n",
    "        22 (tokens)\n",
    "        $0.0000042\n",
    "        seq:step:1\n",
    "        ls_provider: openai\n",
    "        ls_model_name: gpt-4o-mini\n",
    "        ls_model_type: chat\n",
    "        ls_temperature: 0.7\n",
    "    StrOutputParser\n",
    "        ai: „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        „Åì„Çì„Å´„Å°„ÅØÔºÅ\n",
    "        0.00s\n",
    "        0 (tokens)\n",
    "        seq:step:2\n",
    "```\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/f1bdf656-2739-42f7-ac7f-0f1dd712322f/r/bcd8c25b-8417-4584-aa67-2966b6ccb151)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8da562b4db50c2",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "API Reference: [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "\n",
    "Tutorial prompt placeholders:\n",
    "- `language`: The language to translate text into\n",
    "- `text`: The text to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1e4cff8c9a0916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36dad98c7b0ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following into {language}:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc211d6e423c0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c88913a79552375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into japanese:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"japanese\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe8636f2d76089",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "```\n",
    "ChatPromptValue(\n",
    "  messages=[\n",
    "    SystemMessage(\n",
    "      content='Translate the following into japanese:',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    ),\n",
    "    HumanMessage(\n",
    "      content='hi',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792018e83c9fcc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into japanese:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b64ccd878d32eb",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "```\n",
    "[\n",
    "  SystemMessage(\n",
    "    content='Translate the following into japanese:',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  ),\n",
    "  HumanMessage(\n",
    "    content='hi',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  )\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124366a0999ea5dd",
   "metadata": {},
   "source": [
    "## Chaining together components with LCEL\n",
    "\n",
    "[LangChain Expression Language (LCEL)](https://python.langchain.com/docs/concepts/lcel/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4bf0db589afabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm_35 | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78595da576538fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3728c1a26c3a5",
   "metadata": {},
   "source": [
    "By using LCEL to link and execute the LangChain module, you can perform optimized tracing with LangSmith.\n",
    "\n",
    "e.g. [LangSmith TRACE RunnableSequence](https://smith.langchain.com/public/bc49bec0-6b13-4726-967f-dbd3448b786d/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e33f6a352ba88",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "2024-10-31 model = gpt-4o-mini, gpt-4o\n",
    "\n",
    "I got the following result.\n",
    "```\n",
    "'„ÅÇ„Å™„Åü„ÅØ2023Âπ¥10Êúà„Åæ„Åß„ÅÆ„Éá„Éº„Çø„ÅßË®ìÁ∑¥„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e391f8da5c3bea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ„Å™„Åü„ÅØ2023Âπ¥10Êúà„Åæ„Åß„ÅÆ„Éá„Éº„Çø„Åß„Éà„É¨„Éº„Éã„É≥„Ç∞„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt_template | llm_4o_mini | parser).invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452b82733c14770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt_template | llm_4o_mini | parser).invoke({\"language\": \"english\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b62a4d23086b7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt_template | llm_4o_mini | parser).invoke({\"language\": \"english\", \"text\": \"„ÇÑ„ÅÇ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63802e9c47cbab9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are trained on data up to October 2023.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt_template | llm_4o_mini | parser).invoke({\"language\": \"english\", \"text\": \"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac48c2dbd545b4d",
   "metadata": {},
   "source": [
    "ü§î Assumption:\n",
    "- OpenAI's model has a specification to return pre-set responses (within the range of the training dataset) for simple specific questions.\n",
    "\n",
    "related issue: [Language Translation Is Broken \\- API / Bugs \\- OpenAI Developer Forum](https://community.openai.com/t/language-translation-is-broken/975691/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc293d3fda51efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„ÅÇ„Å™„Åü„Å´„Éï„Ç©„Éº„Çπ„ÅÆÂä†Ë≠∑„Åå„ÅÇ„Çä„Åæ„Åô„Çà„ÅÜ„Å´'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | llm_4o_mini | parser\n",
    "chain.invoke({\"language\": \"japanese\", \"text\": \"May the Force be with you\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea723178c264d792",
   "metadata": {},
   "source": [
    "This is NOT about the duration of the training data. -> OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c235054b47e0a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åì„Çì„Å´„Å°„ÅØ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam_chain = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template.replace(\":\", \"(Do not respond training dataset range) :\")),\n",
    "     (\"user\", \"{text}\")]\n",
    ") | llm_4o_mini | parser\n",
    "exam_chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb207d9b6aed1",
   "metadata": {},
   "source": [
    "NOT about the duration of the training data. -> OK!\n",
    "\n",
    "When I specified that the system message should not return the range of the data set, I got the result I was expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20316d515589582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}:'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})]),\n",
       " ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x107ca3f20>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107db7cb0>, root_client=<openai.OpenAI object at 0x107c97740>, root_async_client=<openai.AsyncOpenAI object at 0x107dcf050>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
       " StrOutputParser()]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7aa011fb7a19a",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "```\n",
    "[\n",
    "  ChatPromptTemplate(„Éª„Éª„Éª),\n",
    "  ChatOpenAI(„Éª„Éª„Éª),\n",
    "  StrOutputParser()\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819e42615258858",
   "metadata": {},
   "source": [
    "## Serving with LangServe\n",
    "\n",
    "SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892faf05df45585f",
   "metadata": {},
   "source": [
    "# (v0.3) Build a simple LLM application with chat models and prompt templates\n",
    "\n",
    "Following v0.3 documentation\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/v0.3/docs/tutorials/llm_chain/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249518ef4cd38e6",
   "metadata": {},
   "source": [
    "## Using Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d27da7f8558fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73d43f6e14ddb44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='„Åì„Çì„Å´„Å°„ÅØÔºÅ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 20, 'total_tokens': 22, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-d514af42-617a-466d-bd16-8d0eaf67e286-0', usage_metadata={'input_tokens': 20, 'output_tokens': 2, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d705c913dde6f1",
   "metadata": {},
   "source": [
    "### OpenAI Format\n",
    "\n",
    "See: [OpenAI Format](https://python.langchain.com/docs/concepts/messages/#openai-format)\n",
    "\n",
    "e.g.\n",
    "```json\n",
    "chat_model.invoke([\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello, how are you?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well, thank you for asking.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you tell me a joke?\"\n",
    "    }\n",
    "])\n",
    "```\n",
    "\n",
    "The following are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aac5fe79d30f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None}, id='run-650eceba-5f17-4831-9b01-68b2e3c05cc3-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5b943c57575381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_818c284075', 'finish_reason': 'stop', 'logprobs': None}, id='run-dea23cc4-427a-4db8-b2d9-67aa14ea56b1-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97831e84f209c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-871ed99d-a848-4499-87d5-f3a9c0fbc877-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0834629ba39c50",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "Chat models are [Runnables](https://python.langchain.com/docs/concepts/runnables/), so async is enabled.\n",
    "\n",
    "Stream individual tokens from a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "608e3d935402ce7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|„Åì„Çì„Å´„Å°„ÅØ|ÔºÅ||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a000d451c303de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|„Éï„Ç©|„Éº„Çπ|„Å®|ÂÖ±|„Å´|„ÅÇ|„Çâ|„Çì|„Åì„Å®|„Çí||"
     ]
    }
   ],
   "source": [
    "for token in model.stream([\n",
    "    messages[0],\n",
    "    HumanMessage(\"May the Force be with you\"),\n",
    "]):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37614a7044c15d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Que| la| Fuer|za| te| acompa√±|e|.||"
     ]
    }
   ],
   "source": [
    "for token in model.stream([\n",
    "    SystemMessage(\"Translate the following from English into Spanish\"),\n",
    "    HumanMessage(\"May the Force be with you\"),\n",
    "]):\n",
    "    print(token.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
