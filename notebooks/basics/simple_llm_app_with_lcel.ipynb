{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Build a Simple LLM Application with LCEL\n",
    "\n",
    "ref. [Build a Simple LLM Application with LCEL \\| ðŸ¦œï¸ðŸ”— LangChain](https://python.langchain.com/docs/tutorials/llm_chain/)"
   ],
   "id": "7a2f727e71665314"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "4e76def53c1df9a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### LangSmith\n",
    "\n",
    "> it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.  \n",
    "> The best way to do this is with LangSmith."
   ],
   "id": "edf26bea38384b52"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Using Language Models\n",
    "\n",
    "First, I decided to use the OpenAI language model.  \n",
    "Create .env file under notebooks directory and set the following environment variables.\n",
    "\n",
    "```\n",
    "LANGCHAIN_API_KEY=**********\n",
    "OPENAI_API_KEY=**********\n",
    "```"
   ],
   "id": "3d220446964877af"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-tutorials\""
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ],
   "id": "4d50f2a2233e135c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4\")\n",
    "# maybe not available because of legacy(?)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"text-davinci-003\")\n",
    "# deprecated\n",
    "\n",
    "llm_4o = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_35 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm_cheap = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=100, top_p=0.1)"
   ],
   "id": "89412eff6f3a7662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Japanese\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]"
   ],
   "id": "ca6400e38c95a6ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_4o.invoke(messages)",
   "id": "58cbbf2f3139031a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-4o\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='ã“ã‚“ã«ã¡ã¯ï¼',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-4o-2024-08-06',\n",
    "        'system_fingerprint': 'fp_e5e4913e83',\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "644178b472af2636"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_4o_mini.invoke(messages)",
   "id": "e80759a318159809",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-4o-mini\n",
    "```\n",
    "AIMessage(\n",
    "  content='ã“ã‚“ã«ã¡ã¯ï¼',\n",
    "  additional_kwargs={'refusal': None},\n",
    "  response_metadata={\n",
    "    'token_usage': {\n",
    "      'completion_tokens': 2,\n",
    "      'prompt_tokens': 20,\n",
    "      'total_tokens': 22,\n",
    "      'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "      'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "    },\n",
    "    'model_name': 'gpt-4o-mini-2024-07-18',\n",
    "    'system_fingerprint': 'fp_0ba0d124f1',\n",
    "    'finish_reason': 'stop',\n",
    "    'logprobs': None\n",
    "  },\n",
    "  id='run-**********',\n",
    "  usage_metadata={\n",
    "    'input_tokens': 20,\n",
    "    'output_tokens': 2,\n",
    "    'total_tokens': 22,\n",
    "    'input_token_details': {'cache_read': 0},\n",
    "    'output_token_details': {'reasoning': 0}\n",
    "  }\n",
    ")\n",
    "```"
   ],
   "id": "4f3051cc4ce60ba5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_35.invoke(messages)",
   "id": "eb1944243b17b0c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-3.5-turbo\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='ã“ã‚“ã«ã¡ã¯ï¼',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "8760b1116cd26823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm_cheap.invoke(messages)",
   "id": "7ed42e965a52c2d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "gpt-3.5-turbo, max_tokens=100, top_p=0.1\n",
    "\n",
    "```\n",
    "AIMessage(\n",
    "    content='ã“ã‚“ã«ã¡ã¯ï¼',\n",
    "    additional_kwargs={'refusal': None},\n",
    "    response_metadata={\n",
    "        'token_usage': {\n",
    "            'completion_tokens': 2,\n",
    "            'prompt_tokens': 20,\n",
    "            'total_tokens': 22,\n",
    "            'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0},\n",
    "            'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}\n",
    "        },\n",
    "        'model_name': 'gpt-3.5-turbo-0125',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    id='run-**********',\n",
    "    usage_metadata={\n",
    "        'input_tokens': 20,\n",
    "        'output_tokens': 2,\n",
    "        'total_tokens': 22,\n",
    "        'input_token_details': {'cache_read': 0},\n",
    "        'output_token_details': {'reasoning': 0}\n",
    "    }\n",
    ")\n",
    "```"
   ],
   "id": "63fba7585851ec95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`content` is generated response message.\n",
    "\n",
    "API Reference: [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) | [SystemMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html)\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r)"
   ],
   "id": "d199ee21a423458"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## OutputParsers\n",
    "\n",
    "> We can parse out just this response by using a simple output parser.\n",
    "\n",
    "API Reference: [StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html)"
   ],
   "id": "1b7bc2c1914f1e08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ],
   "id": "318c9810704cb367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llm_4o_mini = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "result = llm_4o_mini.invoke(messages)"
   ],
   "id": "26089f3d247a21b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parser.invoke(result)",
   "id": "8bf9e05b62a78db4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'ã“ã‚“ã«ã¡ã¯ï¼'\n",
    "```"
   ],
   "id": "6498e1e2cabbb5e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = llm_4o_mini | parser",
   "id": "6415a4f21062e26c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain.invoke(messages)",
   "id": "9c4129701ed39886",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'ã“ã‚“ã«ã¡ã¯ï¼'\n",
    "```"
   ],
   "id": "99109fe40fe2036a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LangSmith trace (Extract from my environment)\n",
    "```\n",
    "RunnableSequence\n",
    "    human: hi!\n",
    "    ã“ã‚“ã«ã¡ã¯ï¼\n",
    "    0.98s\n",
    "    22 (tokens)\n",
    "    $0.0000042\n",
    "    ChatOpenAI\n",
    "        human: hi!\n",
    "        ai: ã“ã‚“ã«ã¡ã¯ï¼\n",
    "        0.98s\n",
    "        22 (tokens)\n",
    "        $0.0000042\n",
    "        seq:step:1\n",
    "        ls_provider: openai\n",
    "        ls_model_name: gpt-4o-mini\n",
    "        ls_model_type: chat\n",
    "        ls_temperature: 0.7\n",
    "    StrOutputParser\n",
    "        ai: ã“ã‚“ã«ã¡ã¯ï¼\n",
    "        ã“ã‚“ã«ã¡ã¯ï¼\n",
    "        0.00s\n",
    "        0 (tokens)\n",
    "        seq:step:2\n",
    "```\n",
    "\n",
    "e.g. [Official LangSmith trace](https://smith.langchain.com/public/f1bdf656-2739-42f7-ac7f-0f1dd712322f/r/bcd8c25b-8417-4584-aa67-2966b6ccb151)"
   ],
   "id": "4eb26b80d5467940"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt Templates\n",
    "\n",
    "API Reference: [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n",
    "\n",
    "- `language`: The language to translate text into\n",
    "- `text`: The text to translate"
   ],
   "id": "cb8da562b4db50c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from langchain_core.prompts import ChatPromptTemplate",
   "id": "b1e4cff8c9a0916e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "system_template = \"Translate the following into {language}:\"",
   "id": "e36dad98c7b0ead9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ],
   "id": "dc211d6e423c0446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = prompt_template.invoke({\"language\": \"japanese\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ],
   "id": "2c88913a79552375",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "ChatPromptValue(\n",
    "  messages=[\n",
    "    SystemMessage(\n",
    "      content='Translate the following into japanese:',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    ),\n",
    "    HumanMessage(\n",
    "      content='hi',\n",
    "      additional_kwargs={},\n",
    "      response_metadata={}\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "```"
   ],
   "id": "c5509a6cb5a84364"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result.to_messages()",
   "id": "722e7b2b61656443",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "[\n",
    "  SystemMessage(\n",
    "    content='Translate the following into japanese:',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  ),\n",
    "  HumanMessage(\n",
    "    content='hi',\n",
    "    additional_kwargs={},\n",
    "    response_metadata={}\n",
    "  )\n",
    "]\n",
    "```"
   ],
   "id": "b6b64ccd878d32eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chaining together components with LCEL\n",
    "\n",
    "[LangChain Expression Language (LCEL)](https://python.langchain.com/docs/concepts/lcel/)"
   ],
   "id": "124366a0999ea5dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt_template | llm_35 | parser",
   "id": "e4bf0db589afabcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})",
   "id": "78595da576538fea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'ã“ã‚“ã«ã¡ã¯'\n",
    "```\n",
    "\n",
    "By using LCEL to link and execute the LangChain module, you can perform optimized tracing with LangSmith.\n",
    "\n",
    "e.g. [LangSmith TRACE RunnableSequence](https://smith.langchain.com/public/bc49bec0-6b13-4726-967f-dbd3448b786d/r)"
   ],
   "id": "20e3728c1a26c3a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Note\n",
    "\n",
    "2024-10-31  model = gpt-4o-mini, gpt-4o\n",
    "I got the following result.\n",
    "```\n",
    "'ã‚ãªãŸã¯2023å¹´10æœˆã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚'\n",
    "```\n",
    "\n",
    "ðŸ¤” Assumption:\n",
    "- OpenAI's model has a specification to return pre-set responses (within the range of the training dataset) for simple specific questions."
   ],
   "id": "c29e33f6a352ba88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chain = prompt_template | llm_4o_mini | parser\n",
    "chain.invoke({\"language\": \"japanese\", \"text\": \"May the Force be with you\"})"
   ],
   "id": "f5edd55126ed7f3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'ã‚ãªãŸã«ãƒ•ã‚©ãƒ¼ã‚¹ã®åŠ è­·ãŒã‚ã‚Šã¾ã™ã‚ˆã†ã«ã€‚'\n",
    "```\n",
    "-> OK!"
   ],
   "id": "4389145ff4de60f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exam_chain = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template.replace(\":\", \"(Do not respond training dataset range) :\")),\n",
    "     (\"user\", \"{text}\")]\n",
    ") | llm_4o_mini | parser\n",
    "exam_chain.invoke({\"language\": \"japanese\", \"text\": \"hi\"})"
   ],
   "id": "bafa7efe86dbafa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "'ã“ã‚“ã«ã¡ã¯'\n",
    "```\n",
    "-> OK!  \n",
    "When I specified that the system message should not return the range of the data set, I got the result I was expecting."
   ],
   "id": "49f4fef8604757ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain.steps",
   "id": "d8b402047bf764d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```\n",
    "[\n",
    "  ChatPromptTemplate(ãƒ»ãƒ»ãƒ»),\n",
    "  ChatOpenAI(ãƒ»ãƒ»ãƒ»),\n",
    "  StrOutputParser()\n",
    "]\n",
    "```"
   ],
   "id": "6ee7aa011fb7a19a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9819e42615258858"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f9b582a87cbcf490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "19271d607447bc37",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
