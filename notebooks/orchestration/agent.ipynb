{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539b32e3004e6b19",
   "metadata": {},
   "source": [
    "# Build an Agent\n",
    "\n",
    "ref. [Build an Agent \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/tutorials/agents/)\n",
    "\n",
    "> Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.\n",
    "\n",
    "> We recommend that you use LangGraph for building agents.\n",
    "\n",
    "- [Agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\n",
    "- [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/)\n",
    "\n",
    "This is often achieved via tool-calling.\n",
    "- [Tool calling \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/concepts/tool_calling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd597c071b09b3b",
   "metadata": {},
   "source": [
    "## End-to-end agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7af9eba176b78",
   "metadata": {},
   "source": [
    "### Installation (Additional packages)\n",
    "\n",
    "ref. LangChain Ecosystem: [How to install LangChain packages \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/how_to/installation/)\n",
    "\n",
    "**Integration packages**\n",
    "\n",
    "- **langchain-community**:\n",
    "  - This package contains integrations that haven't been split out into their own packages.\n",
    "  - It serves as a community-driven collection of tools and utilities for LangChain.\n",
    "- **langgraph**:\n",
    "  - It includes functionalities for creating, querying, and visualizing graphs.\n",
    "- **langgraph-checkpoint-sqlite**:\n",
    "  - This package provides checkpointing capabilities for LangGraph using SQLite as the backend.\n",
    "  - It allows users to save and restore the state of their knowledge graphs efficiently.\n",
    "- **tavily-python**:\n",
    "  - This package offers Python bindings for Tavily, a tool or library that is part of the LangChain ecosystem.\n",
    "  - It provides functionalities specific to Tavily's use cases and integrations.\n",
    "\n",
    "> Any integrations that haven't been split out into their own packages will live in the langchain-community package.\n",
    "\n",
    "<img src=\"https://python.langchain.com/assets/images/ecosystem_packages-32943b32657e7a187770c9b585f22a64.png\" width=\"720\" style=\"background-color: white;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32275d0d342642",
   "metadata": {},
   "source": [
    "### LangSmith & Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a990c75f057915c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-tutorials\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1faa545c4c6031c",
   "metadata": {},
   "source": [
    "[Tavily Search \\| ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/integrations/tools/tavily_search/)\n",
    "\n",
    "[Tavily AI | Home](https://app.tavily.com/home)\n",
    "\n",
    "‚ö†Ô∏è **<span style=\"color:red;\">1,000 Requests / Month</span>** (Free plan)\n",
    "\n",
    "It's increasing by **2** per TavilyTool use.\n",
    "\n",
    "`.env`\n",
    "\n",
    "```\n",
    "LANGCHAIN_API_KEY=**********\n",
    "TAVILY_API_KEY=**********\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3657e71d1dd4e1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06ba8b1456ea00",
   "metadata": {},
   "source": [
    "## Define tools\n",
    "\n",
    "Use Tavily to search for information.\n",
    "\n",
    "API Reference: [TavilySearchResults ‚Äî ü¶úüîó LangChain documentation](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6008937e3e13c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Francorchamps', 'region': '', 'country': 'Belgium', 'lat': 50.45, 'lon': 5.95, 'tz_id': 'Europe/Brussels', 'localtime_epoch': 1733507665, 'localtime': '2024-12-06 18:54'}, 'current': {'last_updated_epoch': 1733507100, 'last_updated': '2024-12-06 18:45', 'temp_c': 3.2, 'temp_f': 37.8, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.2, 'wind_kph': 14.8, 'wind_degree': 265, 'wind_dir': 'W', 'pressure_mb': 1017.0, 'pressure_in': 30.03, 'precip_mm': 0.03, 'precip_in': 0.0, 'humidity': 93, 'cloud': 75, 'feelslike_c': -0.4, 'feelslike_f': 31.2, 'windchill_c': 0.2, 'windchill_f': 32.3, 'heatindex_c': 3.7, 'heatindex_f': 38.7, 'dewpoint_c': 2.8, 'dewpoint_f': 37.0, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.0, 'gust_mph': 13.6, 'gust_kph': 21.9}}\"}, {'url': 'https://weather.metoffice.gov.uk/forecast/u0unzv6ce', 'content': 'Spa F1010 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... Use my current location . ... (6 December 2024) Time: 01:00 04:00 07:00 10:00 13:00 16:00 19:00 22:00 Weather symbols: Chance of precipitation : 60%'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in Spa-Francorchamps?\")\n",
    "print(search_results)\n",
    "\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaefa24f93e7c41",
   "metadata": {},
   "source": [
    "e.g.\n",
    "```\n",
    "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Francorchamps', 'region': '', 'country': 'Belgium', 'lat': 50.45, 'lon': 5.95, 'tz_id': 'Europe/Brussels', 'localtime_epoch': 1733404633, 'localtime': '2024-01-01 23:59'}, 'current': {'last_updated_epoch': 1733404500, 'last_updated': '2024-01-01 23:59', 'temp_c': 1.2, 'temp_f': 34.2, 'is_day': 1, 'condition': {'text': 'Light rain', 'icon': '//cdn.weatherapi.com/weather/64x64/day/296.png', 'code': 1183}, 'wind_mph': 17.2, 'wind_kph': 27.7, 'wind_degree': 184, 'wind_dir': 'S', 'pressure_mb': 1015.0, 'pressure_in': 29.97, 'precip_mm': 0.36, 'precip_in': 0.01, 'humidity': 93, 'cloud': 100, 'feelslike_c': -4.7, 'feelslike_f': 23.6, 'windchill_c': -3.9, 'windchill_f': 25.0, 'heatindex_c': 1.8, 'heatindex_f': 35.3, 'dewpoint_c': 0.8, 'dewpoint_f': 33.4, 'vis_km': 5.0, 'vis_miles': 3.0, 'uv': 0.1, 'gust_mph': 27.8, 'gust_kph': 44.8}}\"}, {'url': 'https://gpweather.com/f1/2024/belgium', 'content': 'Complete weather forecast for the F1 2024 Belgian Grand Prix. Get real-time updates on weather conditions and stay up-to-date with the latest forecasts. GP. Weather. ... Spa-Francorchamps circuit. Current weather situation and precipitation forecast. (night) Rain. 0% 0.0mm. Wind. Humidity. 84.4 %. Clouds. 3 %. Pressure. 1025.4 hPa. Visibility.'}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4e3ecf2b8046",
   "metadata": {},
   "source": [
    "## Using Language Models\n",
    "\n",
    "Model: Try to use Anthropic's models in this notebook.\n",
    "- **langchain-anthropic**:\n",
    "  - For Anthropic's AI models (e.g. Claude)\n",
    "\n",
    "See: [Anthropic Console](https://console.anthropic.com/dashboard)\n",
    "\n",
    "`.env`\n",
    "\n",
    "```\n",
    "ANTHROPIC_API_KEY=**********\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4af9239680ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df916817db79a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef22aea3cecda772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content  # By default, the response is a content string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c23d70de006fdf",
   "metadata": {},
   "source": [
    "See: LangSmith\n",
    "\n",
    "e.g.\n",
    "\n",
    "ChatAnthropic: Raw Input\n",
    "```yaml\n",
    "messages:\n",
    "  - - lc: 1\n",
    "      type: constructor\n",
    "      id:\n",
    "        - langchain\n",
    "        - schema\n",
    "        - messages\n",
    "        - HumanMessage\n",
    "      kwargs:\n",
    "        content: hi!\n",
    "        type: human\n",
    "```\n",
    "\n",
    "ChatAnthropic: Raw Output\n",
    "```yaml\n",
    "generations:\n",
    "  - - text: Hello! How can I assist you today? Feel free to ask any questions or let me know if there's anything specific you'd like help with.\n",
    "      generation_info: null\n",
    "      type: ChatGeneration\n",
    "      message:\n",
    "        lc: 1\n",
    "        type: constructor\n",
    "        id:\n",
    "          - langchain\n",
    "          - schema\n",
    "          - messages\n",
    "          - AIMessage\n",
    "        kwargs:\n",
    "          content: Hello! How can I assist you today? Feel free to ask any questions or let me know if there's anything specific you'd like help with.\n",
    "          response_metadata:\n",
    "            id: msg_01RSzg1jq5z3AoTuirnuS3qb\n",
    "            model: claude-3-5-sonnet-20240620\n",
    "            stop_reason: end_turn\n",
    "            stop_sequence: null\n",
    "            usage:\n",
    "              input_tokens: 9\n",
    "              output_tokens: 33\n",
    "          type: ai\n",
    "          id: run-c1b89b2e-49d9-4e20-9a28-16b466edc938-0\n",
    "          usage_metadata:\n",
    "            input_tokens: 9\n",
    "            output_tokens: 33\n",
    "            total_tokens: 42\n",
    "            input_token_details: {}\n",
    "          tool_calls: []\n",
    "          invalid_tool_calls: []\n",
    "llm_output:\n",
    "  id: msg_01RSzg1jq5z3AoTuirnuS3qb\n",
    "  model: claude-3-5-sonnet-20240620\n",
    "  stop_reason: end_turn\n",
    "  stop_sequence: null\n",
    "  usage:\n",
    "    input_tokens: 9\n",
    "    output_tokens: 33\n",
    "run: null\n",
    "type: LLMResult\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed097f8116063885",
   "metadata": {},
   "source": [
    "Give the language model knowledge of these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "405d771694aef917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26cfdfdfefe45a",
   "metadata": {},
   "source": [
    "### Give message NOT to use Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dbe280d4259578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! Welcome. How can I assist you today? I'm here to help with any questions or tasks you might have. Is there something specific you'd like to know or discuss?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389179386b092d0",
   "metadata": {},
   "source": [
    "### Now, try calling it with some input that would expect a tool to be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5876d7684f3c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: [{'text': \"To answer your question about the weather in Spa-Francorchamps, I'll need to search for current information. Let me do that for you.\", 'type': 'text'}, {'id': 'toolu_015CQtCTToZYeLSboRV9jzz8', 'input': {'query': 'current weather in Spa-Francorchamps Belgium'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Spa-Francorchamps Belgium'}, 'id': 'toolu_015CQtCTToZYeLSboRV9jzz8', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in Spa-Francorchamps?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc56408c49229e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: I apologize, but I don't have a specific weather function available to provide real-time weather information for San Francisco. However, I can use the search function to find recent weather reports or forecasts for San Francisco. Would you like me to do that?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in San Francisco?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b80e6bab2490eb",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "e.g. (format modified)\n",
    "```\n",
    "ContentString: [\n",
    "  {\n",
    "    'text': \"To answer your question about the weather in Spa-Francorchamps, I'll need to use a search tool to find the most up-to-date information. Let me do that for you.\",\n",
    "    'type': 'text'\n",
    "  },\n",
    "  {\n",
    "    'id': 'toolu_015PGxS1tMQHs9yAfigDG1om',\n",
    "    'input': {\n",
    "      'query': 'current weather in Spa-Francorchamps, Belgium'\n",
    "    },\n",
    "    'name': 'tavily_search_results_json',\n",
    "    'type': 'tool_use'\n",
    "  }\n",
    "]\n",
    "\n",
    "ToolCalls: [\n",
    "  {\n",
    "    'name': 'tavily_search_results_json',\n",
    "    'args': {\n",
    "      'query': 'current weather in Spa-Francorchamps, Belgium'\n",
    "    },\n",
    "    'id': 'toolu_015PGxS1tMQHs9yAfigDG1om',\n",
    "    'type': 'tool_call'\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "> We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "> This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent.\n",
    "\n",
    "-> ü§î I can see the text content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ae0a61c9d03f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: I apologize, but I don't have access to real-time weather information for San Francisco or any other location. The tools available to me don't include a weather service. \n",
      "\n",
      "However, I can search for recent weather information about San Francisco using the search function. Would you like me to do that?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372bbcf5b9e06e0",
   "metadata": {},
   "source": [
    "**Note*\n",
    "\n",
    "e.g.\n",
    "```\n",
    "ContentString: I apologize, but I don't have access to real-time weather information for San Francisco or any other location. The tools available to me don't include a weather service. However, I can help you find current weather information for San Francisco using a search engine. Would you like me to search for that information?\n",
    "ToolCalls: []\n",
    "```\n",
    "\n",
    "And sometimes Span-Francorchamps is same as SF.:\n",
    "```\n",
    "ContentString: I apologize, but I don't have a specific weather tool available to directly check the current weather conditions in Spa-Francorchamps. However, I can search for recent weather information about this location using the search function available to me. Would you like me to do that?\n",
    "ToolCalls: []\n",
    "```\n",
    "\n",
    "> We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "\n",
    "-> ü§î I can see the text content and empty tool call in spite of the weather question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8479ee181367ea",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "> We will be using [LangGraph](https://python.langchain.com/docs/concepts/architecture/#langgraph) to construct the agent.\n",
    "\n",
    "> highly controllable API in case you want to modify the agent logic.\n",
    "\n",
    "passing in the model, NOT model_with_tools.\n",
    "That is because `create_react_agent` will call `.bind_tools` for us under the hood.\n",
    "\n",
    "API Reference: [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6eb3fa972226138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443f91563f2e4a3",
   "metadata": {},
   "source": [
    "## Run the agent\n",
    "\n",
    "‚ö†Ô∏è Note\n",
    "\n",
    "- These are all stateless queries as long as no setting. (it doesn't remember any previous interactions).\n",
    "- The agent returns a final state at the end of the interaction.\n",
    "  - How to obtain only the outputs will be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509b2266d76a679",
   "metadata": {},
   "source": [
    "### No need to call a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd41ebfb7f05e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='30d3d9bb-31ea-4959-94ec-2f2b63f4dc45'),\n",
       " AIMessage(content=\"Hello! It's nice to meet you. How can I assist you today? I'm here to help with a wide range of topics and questions. Is there anything specific you'd like to know or discuss?\", additional_kwargs={}, response_metadata={'id': 'msg_01GAkGJ4iMjaJSVdGA7JS3AT', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 399, 'output_tokens': 45}}, id='run-d6c7b13f-74a4-4250-bd39-b238dffb05c2-0', usage_metadata={'input_tokens': 399, 'output_tokens': 45, 'total_tokens': 444, 'input_token_details': {}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceffbf45c29dc6fd",
   "metadata": {},
   "source": [
    "See: LangSmith\n",
    "\n",
    "```\n",
    "LangGraph\n",
    "      2.29s 444\n",
    "    __start__\n",
    "          0.00s graph:step:0\n",
    "        agent\n",
    "              2.29s 444 graph:step:1\n",
    "            call_model\n",
    "                  2.28s 444 seq:step:1\n",
    "                RunnableSequence\n",
    "                      2.28s 444 seq:step:1\n",
    "                    StateModifier\n",
    "                          0.00s seq:step:1\n",
    "                    ChatAnthropic claude-3-5-sonnet-20240620\n",
    "                          2.27s 444 seq:step:2\n",
    "            ChannelWrite<agent,messages>\n",
    "                  0.00s seq:step:2\n",
    "            should_continue\n",
    "                  0.00s seq:step:4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8af5245aa43",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "LangSmith: Raw Input\n",
    "\n",
    "```yaml\n",
    "messages:\n",
    "  - content: hi!\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: human\n",
    "    id: 9fbc9581-805a-41a0-8b9a-1853a9a665a1\n",
    "    example: false\n",
    "```\n",
    "\n",
    "LangSmith: Raw Output\n",
    "\n",
    "```yaml\n",
    "messages:\n",
    "  - content: hi!\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: human\n",
    "    id: 9fbc9581-805a-41a0-8b9a-1853a9a665a1\n",
    "    example: false\n",
    "  - content: Hello! It's nice to meet you. How can I assist you today? I'm here to help with any questions or tasks you might have. Is there something specific you'd like to know or discuss?\n",
    "    additional_kwargs: {}\n",
    "    response_metadata:\n",
    "      id: msg_012FxjjJ8UhKAsJcBesYiR6G\n",
    "      model: claude-3-5-sonnet-20240620\n",
    "      stop_reason: end_turn\n",
    "      stop_sequence: null\n",
    "      usage:\n",
    "        input_tokens: 399\n",
    "        output_tokens: 45\n",
    "    type: ai\n",
    "    id: run-515db302-bca7-484e-abe5-48d6176d5a5e-0\n",
    "    example: false\n",
    "    tool_calls: []\n",
    "    invalid_tool_calls: []\n",
    "    usage_metadata:\n",
    "      input_tokens: 399\n",
    "      output_tokens: 45\n",
    "      total_tokens: 444\n",
    "      input_token_details: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e0e6df21f6e60",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "agent: Raw Input\n",
    "```yaml\n",
    "messages:\n",
    "  - content: hi!\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: human\n",
    "    id: 9fbc9581-805a-41a0-8b9a-1853a9a665a1\n",
    "    example: false\n",
    "is_last_step: false\n",
    "remaining_steps: 24\n",
    "```\n",
    "\n",
    "agent: Raw Output\n",
    "```yaml\n",
    "messages:\n",
    "  - content: Hello! It's nice to meet you. How can I assist you today? I'm here to help with any questions or tasks you might have. Is there something specific you'd like to know or discuss?\n",
    "    additional_kwargs: {}\n",
    "    response_metadata:\n",
    "      id: msg_012FxjjJ8UhKAsJcBesYiR6G\n",
    "      model: claude-3-5-sonnet-20240620\n",
    "      stop_reason: end_turn\n",
    "      stop_sequence: null\n",
    "      usage:\n",
    "        input_tokens: 399\n",
    "        output_tokens: 45\n",
    "    type: ai\n",
    "    id: run-515db302-bca7-484e-abe5-48d6176d5a5e-0\n",
    "    example: false\n",
    "    tool_calls: []\n",
    "    invalid_tool_calls: []\n",
    "    usage_metadata:\n",
    "      input_tokens: 399\n",
    "      output_tokens: 45\n",
    "      total_tokens: 444\n",
    "      input_token_details: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23de895ad20a873",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "should_continue: Raw Output\n",
    "\n",
    "```yaml\n",
    "output: __end__\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedf47ec1d7a1ff",
   "metadata": {},
   "source": [
    "### Invoking the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926a05575fe176d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='whats the weather in Spa-Francorchamps?', additional_kwargs={}, response_metadata={}, id='a251111e-984d-4f41-b845-902cffafe111'),\n",
       " AIMessage(content=\"I apologize, but I don't have a specific weather tool available to directly check the current weather in Spa-Francorchamps. However, I can use the search function to find recent weather information for that location. Would you like me to do that?\", additional_kwargs={}, response_metadata={'id': 'msg_01Rw8ovu8hsunJaXBjrtQMRj', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 411, 'output_tokens': 58}}, id='run-a5b3f7f7-afb7-4a45-9c0b-68e60f4cb42b-0', usage_metadata={'input_tokens': 411, 'output_tokens': 58, 'total_tokens': 469, 'input_token_details': {}})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in Spa-Francorchamps?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01628593c2169e",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "[HumanMessage(content='whats the weather in Spa-Francorchamps?', additional_kwargs={}, response_metadata={}, id='4f05a8db-b22a-4b8e-a782-c1890afdb917'),\n",
    " AIMessage(content=\"I apologize, but I don't have a specific weather function available to directly check the current weather in Spa-Francorchamps. However, I can use the search function to find recent weather information for that location. Would you like me to search for the current weather in Spa-Francorchamps?\", additional_kwargs={}, response_metadata={'id': 'msg_01Kijbrvg9iDAWo6V92arDf1', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 411, 'output_tokens': 70}}, id='run-ca42ac7a-5e57-4614-aacc-063d72be6759-0', usage_metadata={'input_tokens': 411, 'output_tokens': 70, 'total_tokens': 481, 'input_token_details': {}})]\n",
    "```\n",
    "\n",
    "In some previous cells, there was a ToolCall, but I don't see it in the output here.\n",
    "\n",
    "ü§î I would guess that the prompt is bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146508684c5123ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='tell me about Spa-Francorchamps weather.', additional_kwargs={}, response_metadata={}, id='254ae376-2370-4854-b758-539f27e155ba'),\n",
       " AIMessage(content=[{'text': \"Certainly! To provide you with accurate and up-to-date information about the weather at Spa-Francorchamps, I'll need to search for the most recent data. Let me use the search tool to find this information for you.\", 'type': 'text'}, {'id': 'toolu_01GyYCJEWR9hiePrRjduhWpz', 'input': {'query': 'Spa-Francorchamps current weather conditions'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01WffLxMjwQtGAD7aPvpZrpt', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 410, 'output_tokens': 121}}, id='run-042f323f-022d-4b5d-9d6e-ceb461b45b25-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Spa-Francorchamps current weather conditions'}, 'id': 'toolu_01GyYCJEWR9hiePrRjduhWpz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 410, 'output_tokens': 121, 'total_tokens': 531, 'input_token_details': {}}),\n",
       " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Francorchamps\\', \\'region\\': \\'\\', \\'country\\': \\'Belgium\\', \\'lat\\': 50.45, \\'lon\\': 5.95, \\'tz_id\\': \\'Europe/Brussels\\', \\'localtime_epoch\\': 1733507665, \\'localtime\\': \\'2024-12-06 18:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1733507100, \\'last_updated\\': \\'2024-12-06 18:45\\', \\'temp_c\\': 3.2, \\'temp_f\\': 37.8, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 9.2, \\'wind_kph\\': 14.8, \\'wind_degree\\': 265, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1017.0, \\'pressure_in\\': 30.03, \\'precip_mm\\': 0.03, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 75, \\'feelslike_c\\': -0.4, \\'feelslike_f\\': 31.2, \\'windchill_c\\': 0.2, \\'windchill_f\\': 32.3, \\'heatindex_c\\': 3.7, \\'heatindex_f\\': 38.7, \\'dewpoint_c\\': 2.8, \\'dewpoint_f\\': 37.0, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.6, \\'gust_kph\\': 21.9}}\"}, {\"url\": \"https://www.holiday-weather.com/francorchamps/forecast/\", \"content\": \"More from Francorchamps Francorchamps Weather Forecast, Liege, Belgium Forecast Belgium Weather The warmest day over the next 25 days weather in Francorchamps is forecast to be Saturday 7th December 2024 at in Francorchamps from this forecast is Francorchamps 8 to 14 Day Forecast Light snow Francorchamps 15 to 21 Day Forecast Francorchamps Day 22 to 26 Day Forecast Holiday Weather Now 14 Day Weather Forecast Francorchamps, Liege,  Belgium Weather now  in Francorchamps is 1¬∞C (34¬∞F) and light rain. Tomorrow it will be 2¬∞C (36¬∞F). The warmest day over the next 25 days weather in Francorchamps is forecast to be Saturday 7th December 2024 at in Francorchamps from this forecast is Hourly Weather Forecast  Next 11 Days Weather Forecast  Francorchamps, Belgium\"}]', name='tavily_search_results_json', id='f6562ea3-9f1b-49d7-8828-7cda526e135a', tool_call_id='toolu_01GyYCJEWR9hiePrRjduhWpz', artifact={'query': 'Spa-Francorchamps current weather conditions', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Spa-Francorchamps', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Francorchamps', 'region': '', 'country': 'Belgium', 'lat': 50.45, 'lon': 5.95, 'tz_id': 'Europe/Brussels', 'localtime_epoch': 1733507665, 'localtime': '2024-12-06 18:54'}, 'current': {'last_updated_epoch': 1733507100, 'last_updated': '2024-12-06 18:45', 'temp_c': 3.2, 'temp_f': 37.8, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.2, 'wind_kph': 14.8, 'wind_degree': 265, 'wind_dir': 'W', 'pressure_mb': 1017.0, 'pressure_in': 30.03, 'precip_mm': 0.03, 'precip_in': 0.0, 'humidity': 93, 'cloud': 75, 'feelslike_c': -0.4, 'feelslike_f': 31.2, 'windchill_c': 0.2, 'windchill_f': 32.3, 'heatindex_c': 3.7, 'heatindex_f': 38.7, 'dewpoint_c': 2.8, 'dewpoint_f': 37.0, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.0, 'gust_mph': 13.6, 'gust_kph': 21.9}}\", 'score': 0.9929222, 'raw_content': None}, {'title': 'Francorchamps Weather Forecast, Liege, Belgium - Holiday Weather', 'url': 'https://www.holiday-weather.com/francorchamps/forecast/', 'content': 'More from Francorchamps Francorchamps Weather Forecast, Liege, Belgium Forecast Belgium Weather The warmest day over the next 25 days weather in Francorchamps is forecast to be Saturday 7th December 2024 at in Francorchamps from this forecast is Francorchamps 8 to 14 Day Forecast Light snow Francorchamps 15 to 21 Day Forecast Francorchamps Day 22 to 26 Day Forecast Holiday Weather Now 14 Day Weather Forecast Francorchamps, Liege,  Belgium Weather now  in Francorchamps is 1¬∞C (34¬∞F) and light rain. Tomorrow it will be 2¬∞C (36¬∞F). The warmest day over the next 25 days weather in Francorchamps is forecast to be Saturday 7th December 2024 at in Francorchamps from this forecast is Hourly Weather Forecast  Next 11 Days Weather Forecast  Francorchamps, Belgium', 'score': 0.98521465, 'raw_content': None}], 'response_time': 3.2}),\n",
       " AIMessage(content=\"Based on the search results, I can provide you with information about the current weather conditions at Spa-Francorchamps. Please note that the data provided is from a weather forecast service and may be a simulated future date, but it gives us a good idea of typical weather patterns for the area.\\n\\nHere's a summary of the weather at Spa-Francorchamps:\\n\\n1. Location: Francorchamps, Belgium\\n2. Temperature: 3.2¬∞C (37.8¬∞F)\\n3. Condition: Partly cloudy\\n4. Wind: 14.8 km/h (9.2 mph), coming from the West\\n5. Humidity: 93%\\n6. Precipitation: Light (0.03 mm)\\n7. Visibility: 10 km (6 miles)\\n8. Feels like: -0.4¬∞C (31.2¬∞F) due to wind chill\\n\\nAdditional details:\\n- Cloud cover: 75%\\n- Pressure: 1017.0 mb\\n- UV index: 0 (likely due to it being nighttime or overcast)\\n\\nIt's worth noting that Spa-Francorchamps is known for its variable and often unpredictable weather. The circuit is located in the Ardennes forest region, which can experience rapid weather changes. This particular weather snapshot shows conditions that are cool, humid, and partly cloudy, which is not uncommon for the area.\\n\\nThe combination of high humidity, cool temperatures, and light precipitation suggests that the track could be damp or have some wet patches, which would be important to consider if this were in the context of motorsports events held at the circuit.\\n\\nRemember that weather conditions can change quickly at Spa-Francorchamps, so if you're planning to visit or are interested in a specific event, it's always good to check for real-time updates closer to the date of interest.\", additional_kwargs={}, response_metadata={'id': 'msg_01SWzz9XXr7Sd4Z7GuJGm5Uh', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1292, 'output_tokens': 427}}, id='run-b477f0a8-1f5f-4c1a-a164-50290e49b9a7-0', usage_metadata={'input_tokens': 1292, 'output_tokens': 427, 'total_tokens': 1719, 'input_token_details': {}})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"tell me about Spa-Francorchamps weather.\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affb83cfd487b3d",
   "metadata": {},
   "source": [
    "-> OK!!\n",
    "\n",
    "‚úÖ In the end, it must be all about the prompts to make the LLM work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bb2c81fd5375b",
   "metadata": {},
   "source": [
    "See: LangSmith\n",
    "\n",
    "e.g.\n",
    "```\n",
    "LangGraph\n",
    "      16.48s 2,106\n",
    "    __start__\n",
    "          0.00s graph:step:0\n",
    "    agent\n",
    "          2.93s 531 graph:step:1\n",
    "        call_model\n",
    "              2.92s 531 seq:step:1\n",
    "            RunnableSequence\n",
    "                  2.92s 531 seq:step:1\n",
    "                StateModifier\n",
    "                      0.00s seq:step:1\n",
    "                ChatAnthropic claude-3-5-sonnet-20240620\n",
    "                      2.92s 531 seq:step:2\n",
    "        ChannelWrite<agent,messages>\n",
    "              0.00s seq:step:2\n",
    "        should_continue\n",
    "              0.00s seq:step:4\n",
    "    tools\n",
    "          3.39s graph:step:2\n",
    "        tavily_search_results_json\n",
    "              3.39s seq:step:1\n",
    "        ChannelWrite<tools,messages>\n",
    "              0.00s seq:step:2\n",
    "    agent\n",
    "          10.16s 1,575 graph:step:3\n",
    "        call_model\n",
    "              10.15s 1,575 seq:step:1\n",
    "            RunnableSequence\n",
    "                  10.15s 1,575 seq:step:1\n",
    "                StateModifier\n",
    "                      0.00s seq:step:1\n",
    "                ChatAnthropic claude-3-5-sonnet-20240620\n",
    "                      10.15s 1,575 seq:step:2\n",
    "        ChannelWrite<agent,messages>\n",
    "              0.00s seq:step:2\n",
    "        should_continue\n",
    "              0.00s seq:step:4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50ebd7b793da02",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "should_continue (1st): Raw Output\n",
    "\n",
    "```yaml\n",
    "output: tools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49263355dedc5209",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "agent (1st): Raw Input\n",
    "\n",
    "```yaml\n",
    "messages:\n",
    "  - content: tell me about Spa-Francorchamps weather.\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: human\n",
    "    id: 46e44c6e-3103-4ea8-a88d-5276d002b1db\n",
    "    example: false\n",
    "is_last_step: false\n",
    "remaining_steps: 24\n",
    "```\n",
    "\n",
    "agent (1st): Raw Output\n",
    "\n",
    "```yaml\n",
    "messages:\n",
    "  - content:\n",
    "      - text: Certainly! To provide you with accurate and up-to-date information about the weather at Spa-Francorchamps, I'll need to search for the most recent data. Let me use the search tool to find this information for you.\n",
    "        type: text\n",
    "      - id: toolu_01RzC8g2WYmvhH6akrBiHEEg\n",
    "        input:\n",
    "          query: Spa-Francorchamps current weather conditions\n",
    "        name: tavily_search_results_json\n",
    "        type: tool_use\n",
    "    additional_kwargs: {}\n",
    "    response_metadata:\n",
    "      id: msg_01PJbrHEakrmfN7tcnJzK37E\n",
    "      model: claude-3-5-sonnet-20240620\n",
    "      stop_reason: tool_use\n",
    "      stop_sequence: null\n",
    "      usage:\n",
    "        input_tokens: 410\n",
    "        output_tokens: 121\n",
    "    type: ai\n",
    "    id: run-fafd2239-fd0e-476a-b6c0-71693fe3307e-0\n",
    "    example: false\n",
    "    tool_calls:\n",
    "      - name: tavily_search_results_json\n",
    "        args:\n",
    "          query: Spa-Francorchamps current weather conditions\n",
    "        id: toolu_01RzC8g2WYmvhH6akrBiHEEg\n",
    "        type: tool_call\n",
    "    invalid_tool_calls: []\n",
    "    usage_metadata:\n",
    "      input_tokens: 410\n",
    "      output_tokens: 121\n",
    "      total_tokens: 531\n",
    "      input_token_details: {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616830ebdd931a2",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "<details>\n",
    "<summary>LangSmith: Raw Output</summary>\n",
    "\n",
    "```yaml\n",
    "messages:\n",
    "  - content: tell me about Spa-Francorchamps weather.\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: human\n",
    "    id: 46e44c6e-3103-4ea8-a88d-5276d002b1db\n",
    "    example: false\n",
    "  - content:\n",
    "      - text: Certainly! To provide you with accurate and up-to-date information about the weather at Spa-Francorchamps, I'll need to search for the most recent data. Let me use the search tool to find this information for you.\n",
    "        type: text\n",
    "      - id: toolu_01RzC8g2WYmvhH6akrBiHEEg\n",
    "        input:\n",
    "          query: Spa-Francorchamps current weather conditions\n",
    "        name: tavily_search_results_json\n",
    "        type: tool_use\n",
    "    additional_kwargs: {}\n",
    "    response_metadata:\n",
    "      id: msg_01PJbrHEakrmfN7tcnJzK37E\n",
    "      model: claude-3-5-sonnet-20240620\n",
    "      stop_reason: tool_use\n",
    "      stop_sequence: null\n",
    "      usage:\n",
    "        input_tokens: 410\n",
    "        output_tokens: 121\n",
    "    type: ai\n",
    "    id: run-fafd2239-fd0e-476a-b6c0-71693fe3307e-0\n",
    "    example: false\n",
    "    tool_calls:\n",
    "      - name: tavily_search_results_json\n",
    "        args:\n",
    "          query: Spa-Francorchamps current weather conditions\n",
    "        id: toolu_01RzC8g2WYmvhH6akrBiHEEg\n",
    "        type: tool_call\n",
    "    invalid_tool_calls: []\n",
    "    usage_metadata:\n",
    "      input_tokens: 410\n",
    "      output_tokens: 121\n",
    "      total_tokens: 531\n",
    "      input_token_details: {}\n",
    "  - content: \"[{\\\"url\\\": \\\"https://www.weatherapi.com/\\\", \\\"content\\\": \\\"{'location': {'name': 'Francorchamps', 'region': '', 'country': 'Belgium', 'lat': 50.45, 'lon': 5.95, 'tz_id': 'Europe/Brussels', 'localtime_epoch': 1733408537, 'localtime': '2024-01-01 23:59'}, 'current': {'last_updated_epoch': 1733408100, 'last_updated': '2024-01-01 23:59', 'temp_c': 1.1, 'temp_f': 34.0, 'is_day': 1, 'condition': {'text': 'Moderate rain', 'icon': '//cdn.weatherapi.com/weather/64x64/day/302.png', 'code': 1189}, 'wind_mph': 16.8, 'wind_kph': 27.0, 'wind_degree': 187, 'wind_dir': 'S', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.51, 'precip_in': 0.02, 'humidity': 100, 'cloud': 100, 'feelslike_c': -4.7, 'feelslike_f': 23.5, 'windchill_c': -3.7, 'windchill_f': 25.4, 'heatindex_c': 1.9, 'heatindex_f': 35.5, 'dewpoint_c': 1.0, 'dewpoint_f': 33.7, 'vis_km': 3.7, 'vis_miles': 2.0, 'uv': 0.0, 'gust_mph': 27.0, 'gust_kph': 43.4}}\\\"}, {\\\"url\\\": \\\"https://gpweather.com/f1/2024/belgium\\\", \\\"content\\\": \\\"Complete weather forecast for the F1 2024 Belgian Grand Prix. Get real-time updates on weather conditions and stay up-to-date with the latest forecasts. GP. Weather. ... Spa-Francorchamps circuit. Current weather situation and precipitation forecast. (night) Rain. 0% 0.0mm. Wind. Humidity. 84.4 %. Clouds. 3 %. Pressure. 1025.4 hPa. Visibility.\\\"}]\"\n",
    "    additional_kwargs: {}\n",
    "    response_metadata: {}\n",
    "    type: tool\n",
    "    name: tavily_search_results_json\n",
    "    id: a19e67c5-ee07-4599-8a69-2e53674e2756\n",
    "    tool_call_id: toolu_01RzC8g2WYmvhH6akrBiHEEg\n",
    "    artifact:\n",
    "      query: Spa-Francorchamps current weather conditions\n",
    "      follow_up_questions: null\n",
    "      answer: null\n",
    "      images: []\n",
    "      results:\n",
    "        - title: Weather in Spa-Francorchamps, Belgium\n",
    "          url: https://www.weatherapi.com/\n",
    "          content: \"{'location': {'name': 'Francorchamps', 'region': '', 'country': 'Belgium', 'lat': 50.45, 'lon': 5.95, 'tz_id': 'Europe/Brussels', 'localtime_epoch': 1733408537, 'localtime': '2024-01-01 23:59'}, 'current': {'last_updated_epoch': 1733408100, 'last_updated': '2024-01-01 23:59', 'temp_c': 1.1, 'temp_f': 34.0, 'is_day': 1, 'condition': {'text': 'Moderate rain', 'icon': '//cdn.weatherapi.com/weather/64x64/day/302.png', 'code': 1189}, 'wind_mph': 16.8, 'wind_kph': 27.0, 'wind_degree': 187, 'wind_dir': 'S', 'pressure_mb': 1014.0, 'pressure_in': 29.94, 'precip_mm': 0.51, 'precip_in': 0.02, 'humidity': 100, 'cloud': 100, 'feelslike_c': -4.7, 'feelslike_f': 23.5, 'windchill_c': -3.7, 'windchill_f': 25.4, 'heatindex_c': 1.9, 'heatindex_f': 35.5, 'dewpoint_c': 1.0, 'dewpoint_f': 33.7, 'vis_km': 3.7, 'vis_miles': 2.0, 'uv': 0.0, 'gust_mph': 27.0, 'gust_kph': 43.4}}\"\n",
    "          score: 0.999753\n",
    "          raw_content: null\n",
    "        - title: 2024 F1 Belgian Grand Prix Weather Forecast\n",
    "          url: https://gpweather.com/f1/2024/belgium\n",
    "          content: Complete weather forecast for the F1 2024 Belgian Grand Prix. Get real-time updates on weather conditions and stay up-to-date with the latest forecasts. GP. Weather. ... Spa-Francorchamps circuit. Current weather situation and precipitation forecast. (night) Rain. 0% 0.0mm. Wind. Humidity. 84.4 %. Clouds. 3 %. Pressure. 1025.4 hPa. Visibility.\n",
    "          score: 0.99936384\n",
    "          raw_content: null\n",
    "      response_time: 2.5\n",
    "    status: success\n",
    "  - content: |-\n",
    "      Based on the search results, I can provide you with information about the current weather conditions at Spa-Francorchamps. Please note that the data provided is a forecast for a future date (December 5, 2024), which is likely the most recent available information from the weather API. Here's a summary of the weather conditions:\n",
    "\n",
    "      1. Location: Francorchamps, Belgium\n",
    "      2. Temperature: 1.1¬∞C (34.0¬∞F)\n",
    "      3. Condition: Moderate rain\n",
    "      4. Wind: 27.0 km/h (16.8 mph), coming from the South\n",
    "      5. Humidity: 100%\n",
    "      6. Cloud cover: 100%\n",
    "      7. Visibility: 3.7 km (2.0 miles)\n",
    "      8. Feels like: -4.7¬∞C (23.5¬∞F) due to wind chill\n",
    "      9. Precipitation: 0.51 mm (0.02 inches) of rain\n",
    "\n",
    "      It's important to note that Spa-Francorchamps is known for its unpredictable and rapidly changing weather conditions. The circuit is located in the Ardennes forest region, which can experience microclimates and sudden weather shifts.\n",
    "\n",
    "      For the upcoming Belgian Grand Prix (as per the second search result), the forecast indicates:\n",
    "\n",
    "      - Some rain is expected\n",
    "      - Humidity is predicted to be around 84.4%\n",
    "      - Cloud cover is expected to be low at 3%\n",
    "      - Atmospheric pressure is forecasted to be 1025.4 hPa\n",
    "\n",
    "      Keep in mind that weather conditions can change quickly, especially in this area. If you're planning to attend an event at Spa-Francorchamps or are just curious about the weather for a specific date, it's advisable to check the forecast closer to the time of interest for the most accurate and up-to-date information.\n",
    "    additional_kwargs: {}\n",
    "    response_metadata:\n",
    "      id: msg_01GcTodKgcqzFgdfBMJAayi6\n",
    "      model: claude-3-5-sonnet-20240620\n",
    "      stop_reason: end_turn\n",
    "      stop_sequence: null\n",
    "      usage:\n",
    "        input_tokens: 1159\n",
    "        output_tokens: 416\n",
    "    type: ai\n",
    "    id: run-e7b2d4ac-f590-4d14-9ddd-3a227302f6cc-0\n",
    "    example: false\n",
    "    tool_calls: []\n",
    "    invalid_tool_calls: []\n",
    "    usage_metadata:\n",
    "      input_tokens: 1159\n",
    "      output_tokens: 416\n",
    "      total_tokens: 1575\n",
    "      input_token_details: {}\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51be5e5104660a",
   "metadata": {},
   "source": [
    "### Draw the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5439fd2a7457c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_mermaid = agent_executor.get_graph().draw_mermaid_png()\n",
    "with open(\"img/agent_tool_graph.png\", \"wb\") as f:\n",
    "    f.write(png_mermaid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1fc9e25ace07f",
   "metadata": {},
   "source": [
    "![agent_tool_graph.png](img/agent_tool_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61784611dd6012",
   "metadata": {},
   "source": [
    "## Streaming Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e63fa264c7922f",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4a0d432d89bf1",
   "metadata": {},
   "source": [
    "## Adding in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a401661d35ed3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "For more information on Agents\n",
    "\n",
    "- [LangGraph overview](https://langchain-ai.github.io/langgraph/concepts/high_level/#core-principles)\n",
    "- [LangGraph Academy Course](https://academy.langchain.com/courses/intro-to-langgraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
